# Читаем данные из csv
my_df <- read.csv("normal_NYK_and_Healthy_new_data for viewing.csv", sep=";")

# Строим бинарную логистическую регрессионную модель
fit <- glm(class ~ predict1 + predict2 + predict3 + predict4 + predict5 + predict6 + predict7 + predict8 + predict9 + predict10, my_df, family = "binomial")

# Предсказываем вероятность в масштабе предсказуемого значения (class), т.е. от 0 до 1
prob <- predict(object = fit, type = "response")

library(ROCR)

# Для дальнейших вычислений необходимо, чтобы данные хранились в виде объекта, используемого библиотекой ROCR
# следующей командой создаем этот объект (предсказанные вероятности + требуемые результирующие значения)
pred_fit <- prediction(prob, my_df$class)

# Находим специфичность решений
# Это вектор зависимостей между порогом классификации и числом правильных ответов для класса "1", т.к. у нас бинарная модель
perf3  <- performance(pred_fit, x.measure = "cutoff", measure = "spec")

# Находим чувствительность решений
# Это вектор зависимостей между порогом классификации и числом правильных ответов для класса "0", т.к. у нас бинарная модель
perf4  <- performance(pred_fit, x.measure = "cutoff", measure = "sens")

# Отобразим обе зависимости на графике
plot(perf3, col = "red", lwd =2)
plot(add=T, perf4 , col = "green", lwd =2)

# После анализа графика зависимостей, становится ясно, что следует выбрать порог классификации, равный 0.56
# т.к. при данном пороге модель имеет минимальное количество ошибок и максимальное количество правильных ответов по обоим классам
abline(v= 0.56, lwd = 2)

# Используя полученную вероятность и порог классификации, составим вектор ответов для нашей модели
pred_resp  <- factor(ifelse(prob > 0.56, 1, 0))

# и вектор учета правильных ответов относительно исходных значений (class)
correct  <- ifelse(pred_resp == my_df$class, 1, 0)

# Рассчитаем среднее число правильных ответов модели: 77.5%
mean(correct)
